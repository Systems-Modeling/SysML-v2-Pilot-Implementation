"""
EBNF Extractor for KerML and SysML specifications in HTML format

@author: Hans Peter de Koning (DEKonsult)

Note: Needs package beautifulsoup4 (See https://pypi.org/project/beautifulsoup4/)
"""
import sys
import re
from datetime import datetime, timezone
from bs4 import BeautifulSoup
from typing import Optional

# Create logger for debug, info, warning, error, critical messages
import logging
LOGGER = logging.getLogger()
LOGGER.setLevel(logging.DEBUG)

def line_comment(text: str):
    return f"# {text}\n"

def block_comment(texts: list[str], add_newline: bool = True):
    text = f"# {'\n# '.join(texts)}\n"
    if add_newline:
        text += "\n"
    return text

def warn_about_non_ascii_chars(text: str):
    is_ascii = text is None or text.isascii()
    if not is_ascii:
        non_ascii_chars: set[str] = set()
        for ch in text:
            if not ch.isascii():
                non_ascii_chars.add(ch)
        LOGGER.warning(f"Found non_ascii_chars: {sorted(non_ascii_chars)}")

def get_clean_text_content(text: Optional[str], correct_comma_dot: bool = False) -> str:
    if text is None:
        text = ""
    text = text.replace("Â ", " ")
    if correct_comma_dot:
        text = text.replace(" ,", ",")
        text = text.replace(" .", ".")
    text = text.rstrip()
    # Replace leading space(s) followed by newline(s) with a single newline
    LEADING_SPACE_NL_PATTERN = re.compile(r"^ +\n+")
    text = LEADING_SPACE_NL_PATTERN.sub("\n", text)
    return text

def extract_ebnf(html_spec_path: str, ebnf_spec_path: str, textual_notation_clause_number: str):
    with open(html_spec_path, mode="r", encoding="utf-8") as html_spec:
        soup = BeautifulSoup(html_spec, "html.parser")

    ebnf_spec = open(ebnf_spec_path, mode="w", encoding="utf-8")

    ebnf_spec.write(line_comment(f"Source document: {html_spec_path}\n"))
    ebnf_spec.write(line_comment(f"Generated by ebnf_extractor at: {start_timestamp}\n"))

    reserved_keyword_set: set[str] = set()
    extracted_keyword_set: set[str] = set()

    inside_textual_notation_clause = False
    contains_note_reference = False
    contains_notes_section = False
    inside_reserved_symbols = False
    count = 0
    clause_number = ""
    clause_title = ""

    # Walk through all HTML elements (tags) and extract EBNF productions (and notes) from the Textual Notation clause
    for tag in soup.find_all():
        count += 1

        if tag.name == "h1":
            # Process clause / section header
            contains_note_reference = False
            contains_notes_section = False
            inside_reserved_symbols = False
            # LOGGER.debug(f"tag{count}={tag}")

            class_attribute = tag.attrs.get("class")
            if class_attribute and "view-title" in class_attribute:
                # LOGGER.debug(f"view-title tag={tag}")
                clause_number = tag.find("span", {"class": "ve-view-number"}).string
                clause_number = clause_number.strip() if clause_number else ""
                clause_title = tag.find("transclude-name").find("span").string
                clause_title = clause_title.strip() if clause_title else ""
                LOGGER.debug(f"clause={clause_number} {clause_title}")

                if clause_number == textual_notation_clause_number:
                    inside_textual_notation_clause = True
                    LOGGER.debug(f"inside_textual_notation_clause={inside_textual_notation_clause}")
                elif inside_textual_notation_clause and not clause_number.startswith(textual_notation_clause_number):
                    inside_textual_notation_clause = False
                    LOGGER.debug(f"inside_textual_notation_clause={inside_textual_notation_clause}")

                if inside_textual_notation_clause:
                    ebnf_spec.write(line_comment(f"Clause {clause_number} {clause_title}\n"))

        elif tag.name == "pre" and inside_textual_notation_clause:
            # Process <pre> element that contains the EBNF grammar lines
            LOGGER.debug(f"tag#{count}:\n{tag}")

            for subtag in tag:

                if subtag.name is None or subtag.name == "strong":
                    # The subtag has only string content or is enclosed in <strong>
                    text_content = get_clean_text_content(subtag.string)
                    warn_about_non_ascii_chars(text_content)
                    first_word = text_content.split()[0] if text_content else ""
                    # if first_word.isupper():
                    #     # Assume it's a lexical token declaration
                    #     text_content = get_clean_text_content(" ".join(tag.stripped_strings))
                    #     ebnf_spec.write(text_content)
                    #     ebnf_spec.write("\n\n")
                    #     # Skip rest of subtags
                    #     continue

                    if text_content != "":
                        KEYWORD_PATTERN = re.compile(r"('[a-z]{2,}'|'@'|'$')")
                        matched_keywords = KEYWORD_PATTERN.findall(text_content)
                        for matched_keyword in matched_keywords:
                            if not matched_keyword.startswith("{"):
                                extracted_keyword_set.add(matched_keyword[1:-1])

                        if (clause_title == "Lexical Structure" or clause_title == "Reserved Words") and not "=" in text_content:
                            # This <pre> element contains the list of reserved keywords
                            reserved_keyword_set = set(text_content.strip().split())
                            reserved_keywords_block = ["RESERVED_KEYWORD ="]
                            is_first = True
                            for symbol in sorted(reserved_keyword_set):
                                if is_first:
                                    reserved_keywords_block.append(f"      '{symbol}'")
                                    is_first = False
                                else:
                                    reserved_keywords_block.append(f"    | '{symbol}'")
                            ebnf_spec.write(block_comment(reserved_keywords_block))
                        elif (clause_title == "Symbols" and not text_content.startswith("TYPED_BY")):
                            reserved_symbol_set = set(text_content.strip().split())
                            if not inside_reserved_symbols:
                                reserved_symbols_block = ["RESERVED_SYMBOLS ="]
                                is_first = True
                            else:
                                reserved_symbols_block = []
                            for symbol in sorted(reserved_symbol_set):
                                if is_first:
                                    reserved_symbols_block.append(f"      '{symbol}'")
                                    is_first = False
                                else:
                                    reserved_symbols_block.append(f"    | '{symbol}'")
                            ebnf_spec.write(block_comment(reserved_symbols_block, False))
                            if inside_reserved_symbols:
                                ebnf_spec.write("\n")
                            inside_reserved_symbols = True
                        else:
                            ebnf_spec.write(text_content)
                            ebnf_spec.write("\n\n")

                elif subtag.name == "em":
                    text_content = get_clean_text_content(subtag.contents[0]).strip().replace("see", "See")
                    if text_content:
                        if text_content.startswith("(See"):
                            ebnf_spec.write(line_comment(text_content))
                            contains_note_reference = True
                        else:
                            LOGGER.warning(f"<em> subtag without grammar: tag={subtag}")
                            ebnf_spec.write(f"<em>{text_content}</em>")
                    else:
                        LOGGER.warning(f"Empty <em> subtag={subtag}")

                else:
                    LOGGER.error(f"Unexpected tag inside <pre> element: tag={subtag}")

        elif tag.name == "p" and inside_textual_notation_clause and contains_note_reference:
            # LOGGER.debug(f"note <p> tag={tag}")
            if tag.string == "Notes":
                contains_notes_section = True

        elif tag.name == "ol" and inside_textual_notation_clause and contains_notes_section:
            # LOGGER.debug(f"note <ol> tag={tag}")
            list_item_count = 0
            ebnf_spec.write("\n")
            for subtag in tag:
                if subtag.name == "li":
                    list_item_count += 1
                    text_content = get_clean_text_content(" ".join(subtag.stripped_strings), True)
                    note_content = f"Note {list_item_count}: {text_content}"
                    ebnf_spec.write(line_comment(note_content))
                    LOGGER.debug(f"note_contents={note_content}")
            ebnf_spec.write("\n")
            contains_note_reference = False
            contains_notes_section = False

    ebnf_spec.write(line_comment("End of EBNF"))
    ebnf_spec.write("\n")

    # Check declared and scanned keywords, and report
    extracted_keywords_block = []
    extracted_keywords_block.append("EBNF Grammar Checks")
    extracted_keywords_block.append("")
    extracted_keywords_block.append("Keywords extracted from EBNF grammar scan:")
    extracted_keywords_block.extend([f"  '{kw}'" for kw in sorted(extracted_keyword_set)])
    ebnf_spec.write(block_comment(extracted_keywords_block))

    reserved_set_diff_extracted = reserved_keyword_set - extracted_keyword_set
    reserved_set_diff_extracted_list = ", ".join(sorted(reserved_set_diff_extracted))

    extracted_set_diff_reserved = extracted_keyword_set - reserved_keyword_set
    extracted_set_diff_reserved_list = ", ".join(sorted(extracted_set_diff_reserved))

    comparison_block = []
    comparison_block.append("Comparison of declared reserved keywords versus extracted keywords")
    comparison_block.append("")
    comparison_block.append("Declared reserved keywords not in extracted keywords:")
    comparison_block.append(f"  {reserved_set_diff_extracted_list}")
    comparison_block.append("")
    comparison_block.append("Extracted keywords not in declared reserved keywords:")
    comparison_block.append(f"  {extracted_set_diff_reserved_list}")
    ebnf_spec.write(block_comment(comparison_block))

    ebnf_spec.write(line_comment("End of EBNF Grammar Checks"))

    ebnf_spec.close()

# Main program
if __name__ == "__main__":
    # Create message logger on console
    consoleHandler = logging.StreamHandler(sys.stdout)
    consoleHandler.setLevel(logging.DEBUG)
    consoleHandler.setFormatter(logging.Formatter("%(levelname)-8s: %(message)s"))
    LOGGER.addHandler(consoleHandler)

    start_timestamp = datetime.now(timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z")
    LOGGER.info(f"Run started at {start_timestamp}")

    html_spec_path = "data/Part 1 - Kernel Modeling Language (KerML)-r2025-02--2025-03-21.html"
    ebnf_spec_path = "data/kerml_ebnf.txt"
    textual_notation_clause_number = "8.2"

    # html_spec_path = "data/Part 2 - Systems Modeling Language (SysML)-r2025-02--2025-03-19-source.html"
    # ebnf_spec_path = "data/sysml_v2_ebnf.txt"
    # textual_notation_clause_number = "8.2.2"

    extract_ebnf(html_spec_path, ebnf_spec_path, textual_notation_clause_number)
